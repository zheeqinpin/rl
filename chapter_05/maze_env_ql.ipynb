{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 这是一个实现了qlearning的迷宫环境 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import logging\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "from gym import spaces\n",
    "import gym\n",
    "from collections import defaultdict\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "class MazeEnvQl(gym.Env):\n",
    "    #添加元数据，改变渲染环境时的参数\n",
    "    metadata = {\n",
    "        'render.modes': ['human', 'rgb_array'],\n",
    "        'video.frames_per_second': 2\n",
    "    }\n",
    "\n",
    "    def __init__(self):\n",
    "\n",
    "        self.states = [1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18] #状态空间\n",
    "        self.x=[140,220,300,460,140,220,300,460,300,380,460,140,220,300,380,460,140,220]\n",
    "        self.y=[460,460,460,460,380,380,380,380,300,300,300,220,220,220,220,220,140,140]\n",
    "        self.terminate_states = dict()  #终止状态为字典格式\n",
    "        self.terminate_states[16] = 1\n",
    "\n",
    "        self.actions = ['n','e','s','w']\n",
    "\n",
    "        self.rewards = dict();        #回报的数据结构为字典\n",
    "        self.rewards['11_s'] = 10.0\n",
    "        self.rewards['15_e'] = 10.0\n",
    "\n",
    "        self.t = dict();             #状态转移的数据格式为字典\n",
    "        self.t['1_s'] = 5\n",
    "        self.t['1_e'] = 2\n",
    "        \n",
    "        self.t['2_w'] = 1\n",
    "        self.t['2_e'] = 3\n",
    "        self.t['2_s'] = 6\n",
    "        \n",
    "        self.t['3_s'] = 7\n",
    "        self.t['3_w'] = 2\n",
    "        \n",
    "        self.t['4_s'] = 8\n",
    "        \n",
    "        self.t['5_n'] = 1\n",
    "        self.t['5_e'] = 6\n",
    "        \n",
    "        self.t['6_e'] = 7\n",
    "        self.t['6_w'] = 5\n",
    "        self.t['6_n'] = 2\n",
    "        \n",
    "        self.t['7_s'] = 9\n",
    "        self.t['7_w'] = 6\n",
    "        self.t['7_n'] = 3\n",
    "        \n",
    "        self.t['8_s'] = 11\n",
    "        self.t['8_n'] = 4\n",
    "        \n",
    "        self.t['9_e'] = 10\n",
    "        self.t['9_s'] = 14\n",
    "        self.t['9_n'] = 7\n",
    "        \n",
    "        self.t['10_s'] = 15\n",
    "        self.t['10_w'] = 9\n",
    "        self.t['10_e'] = 11\n",
    "        \n",
    "        self.t['11_w'] = 10\n",
    "        self.t['11_s'] = 16\n",
    "        self.t['11_n'] = 8\n",
    "        \n",
    "        self.t['12_e'] = 13\n",
    "        self.t['12_s'] = 17\n",
    "        \n",
    "        self.t['13_e'] = 14\n",
    "        self.t['13_s'] = 18\n",
    "        self.t['13_w'] = 12\n",
    "        \n",
    "        self.t['14_e'] = 15\n",
    "        self.t['14_w'] = 13\n",
    "        self.t['14_n'] = 9\n",
    "        \n",
    "        self.t['15_e'] = 16\n",
    "        self.t['15_w'] = 14\n",
    "        self.t['15_n'] = 10\n",
    "        \n",
    "        self.t['17_n'] = 12\n",
    "        self.t['17_e'] = 18\n",
    "        \n",
    "        self.t['18_n'] = 13\n",
    "        self.t['18_w'] = 17\n",
    "        \n",
    "        self.gamma = 0.9         #折扣因子\n",
    "        self.viewer = None\n",
    "        self.state = None\n",
    "        self.mc_policy = None\n",
    "\n",
    "    def getTerminal(self):\n",
    "        return self.terminate_states\n",
    "\n",
    "    def getGamma(self):\n",
    "        return self.gamma\n",
    "\n",
    "    def getStates(self):\n",
    "        return self.states\n",
    "\n",
    "    def getAction(self):\n",
    "        return self.actions\n",
    "    def getTerminate_states(self):\n",
    "        return self.terminate_states\n",
    "    def setAction(self,s):\n",
    "        self.state=s\n",
    "    def transform(self, state, action):\n",
    "        if state in self.terminate_states:\n",
    "            return state, 0, True, {}\n",
    "        key = \"%d_%s\"%(state, action)   #将状态和动作组成字典的键值\n",
    "\n",
    "        #状态转移\n",
    "        if key in self.t:\n",
    "            next_state = self.t[key]\n",
    "        else:\n",
    "            next_state = state\n",
    "        is_terminal = False\n",
    "\n",
    "        if next_state in self.terminate_states:\n",
    "            is_terminal = True\n",
    "\n",
    "        if key not in self.rewards:\n",
    "            r = 0.0\n",
    "        else:\n",
    "            r = self.rewards[key]\n",
    "        return next_state, r,is_terminal,{}\n",
    "####################################################################################################\n",
    "    #  贪婪策略\n",
    "    def greedy(self, qfunc, state):\n",
    "        amax = self.actions[0]\n",
    "        key = \"%d_%s\" % (state, amax)\n",
    "        qmax = qfunc[key]\n",
    "        for action in self.actions:  # 扫描动作空间得到最大动作值函数\n",
    "            key1 = \"%d_%s\" % (state, action)\n",
    "            q = qfunc[key1]\n",
    "            if qmax < q:\n",
    "                qmax = q\n",
    "                amax = action\n",
    "        return amax\n",
    "    #######epsilon贪婪策略\n",
    "    def epsilon_greedy(self, qfunc, state, epsilon):\n",
    "        amax = self.actions[0]\n",
    "        key = \"%d_%s\"%(state, amax)\n",
    "        qmax = qfunc[key]\n",
    "        for action in self.actions:    #扫描动作空间得到最大动作值函数\n",
    "            key = \"%d_%s\"%(state, action)\n",
    "            q = qfunc[key]\n",
    "            if qmax < q:\n",
    "                qmax = q\n",
    "                amax = action\n",
    "        #概率部分\n",
    "        pro = pd.Series(data=np.zeros(shape=len(self.actions)), index=self.actions)\n",
    "        pro[amax] += 1-epsilon\n",
    "        for action1 in self.actions:\n",
    "            pro[action1] += epsilon/len(self.actions)\n",
    "        ##选择动作\n",
    "        r = random.random()\n",
    "        s = 0.0\n",
    "        for action2 in self.actions:\n",
    "            s += pro[action2]\n",
    "            if s>= r: return action2\n",
    "        return self.actions[len(self.actions)-1]\n",
    "\n",
    "    def qlearning(self, num_iter1, alpha, epsilon):\n",
    "        qfunc = dict()   #行为值函数为字典\n",
    "        #初始化行为值函数为0\n",
    "        for s in self.states:\n",
    "            for a in self.actions:\n",
    "                key = \"%d_%s\"%(s,a)\n",
    "                qfunc[key] = 0.0\n",
    "        for iter1 in range(num_iter1):\n",
    "#             x.append(iter1)\n",
    "#             y.append(compute_error(qfunc))\n",
    "            #初始化初始状态\n",
    "            s = self.states[int(random.random() * len(self.states))]\n",
    "            a = self.actions[int(random.random()*len(self.actions))]\n",
    "            t1 = False\n",
    "            while False == t1:\n",
    "                key = \"%d_%s\"%(s, a)\n",
    "                #与环境进行一次交互，从环境中得到新的状态及回报\n",
    "                next_state, r, t1, i =self.transform(s, a)\n",
    "                #next_state处的最大动作\n",
    "                a1 = self.greedy(qfunc, next_state)\n",
    "                key1 = \"%d_%s\"%(next_state, a1)\n",
    "                #利用qlearning方法更新值函数\n",
    "                qfunc[key] = qfunc[key] + alpha*(r + self.gamma * qfunc[key1]-qfunc[key])\n",
    "                #转到下一个状态\n",
    "                s = next_state;\n",
    "                a = self.epsilon_greedy(qfunc, next_state, epsilon)\n",
    "        return qfunc\n",
    "    def getBestPolicy(self, num_iter1, alpha, epsilon):\n",
    "        qfunc = self.qlearning(num_iter1, alpha, epsilon)\n",
    "        policy = pd.Series(index=self.states)\n",
    "        for state in self.states:\n",
    "            amax = self.actions[0]\n",
    "            key = \"%d_%s\" % (state, amax)\n",
    "            qmax = qfunc[key]\n",
    "            for action in self.actions:  # 扫描动作空间得到最大动作值函数\n",
    "                key1 = \"%d_%s\" % (state, action)\n",
    "                q = qfunc[key1]\n",
    "                if qmax < q:\n",
    "                    qmax = q\n",
    "                    amax = action\n",
    "            policy[state] = amax\n",
    "        return policy\n",
    "####################################################################################################\n",
    "    def step(self, action):\n",
    "        #系统当前状态\n",
    "        state = self.state\n",
    "        if state in self.terminate_states:\n",
    "            return state, 0, True, {}\n",
    "        key = \"%d_%s\"%(state, action)   #将状态和动作组成字典的键值\n",
    "\n",
    "        #状态转移\n",
    "        if key in self.t:\n",
    "            next_state = self.t[key]\n",
    "        else:\n",
    "            next_state = state\n",
    "        self.state = next_state\n",
    "\n",
    "        is_terminal = False\n",
    "\n",
    "        if next_state in self.terminate_states:\n",
    "            is_terminal = True\n",
    "\n",
    "        if key not in self.rewards:\n",
    "            r = 0.0\n",
    "        else:\n",
    "            r = self.rewards[key]\n",
    "        return next_state, r,is_terminal,{}\n",
    "    def reset(self):\n",
    "        self.state = self.states[int(random.random() * len(self.states))]\n",
    "        return self.state\n",
    "    def myreset(self):\n",
    "        self.state = 1\n",
    "        return self.state\n",
    "    def seed(self, seed=None):\n",
    "        self.np_random, seed = seeding.np_random(seed)\n",
    "        return [seed]\n",
    "    def render(self, mode='human', close=False):\n",
    "        if close:\n",
    "            if self.viewer is not None:\n",
    "                self.viewer.close()\n",
    "                self.viewer = None\n",
    "            return\n",
    "        screen_width = 600\n",
    "        screen_height = 600\n",
    "\n",
    "        if self.viewer is None:\n",
    "            from gym.envs.classic_control import rendering\n",
    "            self.viewer = rendering.Viewer(screen_width, screen_height)\n",
    "            #创建网格世界\n",
    "            self.line1 = rendering.Line((100, 260),(500, 260))\n",
    "            self.line2 = rendering.Line((100, 180),(500, 180))\n",
    "            self.line3 = rendering.Line((100, 100),(500, 100))\n",
    "            self.line4 = rendering.Line((100, 340),(500, 340))\n",
    "            self.line5 = rendering.Line((100, 420),(500, 420))\n",
    "            self.line6 = rendering.Line((100, 500),(500, 500))\n",
    "            \n",
    "            self.line7 = rendering.Line((100, 500), (100, 100))\n",
    "            self.line8 = rendering.Line((180, 500), (180, 100))\n",
    "            self.line9 = rendering.Line((260, 500), (260, 100))\n",
    "            self.line10 = rendering.Line((340, 500), (340, 100))\n",
    "            self.line11 = rendering.Line((420, 500), (420, 100))\n",
    "            self.line12 = rendering.Line((500, 500), (500, 100))\n",
    "\n",
    "            #创建第一个骷髅\n",
    "            self.kulo1 = rendering.make_circle(40)\n",
    "            self.circletrans = rendering.Transform(translation=(380,460))\n",
    "            self.kulo1.add_attr(self.circletrans)\n",
    "            self.kulo1.set_color(0,0,0)\n",
    "            #创建第二个骷髅\n",
    "            self.kulo2 = rendering.make_circle(40)\n",
    "            self.circletrans = rendering.Transform(translation=(380, 380))\n",
    "            self.kulo2.add_attr(self.circletrans)\n",
    "            self.kulo2.set_color(0, 0, 0)\n",
    "            \n",
    "            self.gold1 = rendering.make_circle(40)\n",
    "            self.circletrans = rendering.Transform(translation=(140, 300))\n",
    "            self.gold1.add_attr(self.circletrans)\n",
    "            self.gold1.set_color(0, 0, 0)\n",
    "            \n",
    "            self.gold2 = rendering.make_circle(40)\n",
    "            self.circletrans = rendering.Transform(translation=(220, 300))\n",
    "            self.gold2.add_attr(self.circletrans)\n",
    "            self.gold2.set_color(0, 0, 0)\n",
    "            \n",
    "            self.gold3 = rendering.make_circle(40)\n",
    "            self.circletrans = rendering.Transform(translation=(300, 140))\n",
    "            self.gold3.add_attr(self.circletrans)\n",
    "            self.gold3.set_color(0, 0, 0)\n",
    "            \n",
    "            self.gold4 = rendering.make_circle(40)\n",
    "            self.circletrans = rendering.Transform(translation=(380, 140))\n",
    "            self.gold4.add_attr(self.circletrans)\n",
    "            self.gold4.set_color(0, 0, 0)\n",
    "            \n",
    "            self.gold5 = rendering.make_circle(40)\n",
    "            self.circletrans = rendering.Transform(translation=(460, 140))\n",
    "            self.gold5.add_attr(self.circletrans)\n",
    "            self.gold5.set_color(0, 0, 0)\n",
    "            self.gold6 = rendering.make_circle(40)\n",
    "            self.circletrans = rendering.Transform(translation=(460, 220))\n",
    "            self.gold6.add_attr(self.circletrans)\n",
    "            self.gold6.set_color(1, 0.9, 0)\n",
    "            \n",
    "            \n",
    "        \n",
    "            #创建机器人\n",
    "            self.robot= rendering.make_circle(30)\n",
    "            self.robotrans = rendering.Transform()\n",
    "            self.robot.add_attr(self.robotrans)\n",
    "            self.robot.set_color(0.8, 0.6, 0.4)\n",
    "\n",
    "            self.line1.set_color(0, 0, 0)\n",
    "            self.line2.set_color(0, 0, 0)\n",
    "            self.line3.set_color(0, 0, 0)\n",
    "            self.line4.set_color(0, 0, 0)\n",
    "            self.line5.set_color(0, 0, 0)\n",
    "            self.line6.set_color(0, 0, 0)\n",
    "            self.line7.set_color(0, 0, 0)\n",
    "            self.line8.set_color(0, 0, 0)\n",
    "            self.line9.set_color(0, 0, 0)\n",
    "            self.line10.set_color(0, 0, 0)\n",
    "            self.line11.set_color(0, 0, 0)\n",
    "            self.line12.set_color(0, 0, 0)\n",
    "\n",
    "            self.viewer.add_geom(self.line1)\n",
    "            self.viewer.add_geom(self.line2)\n",
    "            self.viewer.add_geom(self.line3)\n",
    "            self.viewer.add_geom(self.line4)\n",
    "            self.viewer.add_geom(self.line5)\n",
    "            self.viewer.add_geom(self.line6)\n",
    "            self.viewer.add_geom(self.line7)\n",
    "            self.viewer.add_geom(self.line8)\n",
    "            self.viewer.add_geom(self.line9)\n",
    "            self.viewer.add_geom(self.line10)\n",
    "            self.viewer.add_geom(self.line11)\n",
    "            self.viewer.add_geom(self.line12)\n",
    "            self.viewer.add_geom(self.kulo1)\n",
    "            self.viewer.add_geom(self.kulo2)\n",
    "            self.viewer.add_geom(self.gold1)\n",
    "            self.viewer.add_geom(self.gold2)\n",
    "            self.viewer.add_geom(self.gold3)\n",
    "            self.viewer.add_geom(self.gold4)\n",
    "            self.viewer.add_geom(self.gold5)\n",
    "            self.viewer.add_geom(self.gold6)\n",
    "            self.viewer.add_geom(self.robot)\n",
    "\n",
    "        if self.state is None: return None\n",
    "        #self.robotrans.set_translation(self.x[self.state-1],self.y[self.state-1])\n",
    "        self.robotrans.set_translation(self.x[self.state-1], self.y[self.state- 1])\n",
    "\n",
    "\n",
    "\n",
    "        return self.viewer.render(return_rgb_array=mode == 'rgb_array')\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
